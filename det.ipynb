{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named caffe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7149921b4a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#caffe.set_device(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named caffe"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import time\n",
    "import math\n",
    "from nms import nms\n",
    "from crop_image import crop_image\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "caffe_root = './'  # this file is expected to be in {caffe_root}/examples\n",
    "import os\n",
    "os.chdir(caffe_root)\n",
    "import sys\n",
    "sys.path.insert(0, 'python')\n",
    "\n",
    "import caffe\n",
    "#caffe.set_device(0)\n",
    "caffe.set_mode_cpu()\n",
    "\n",
    "\n",
    "def prepare_network(config):\n",
    "\tnet = caffe.Net(config['model_def'],\t # defines the structure of the model\n",
    "                config['model_weights'],  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "\ttransformer = caffe.io.Transformer({'data': (1,3,config['input_height'], config['input_width'])})\n",
    "\ttransformer.set_transpose('data', (2, 0, 1))\n",
    "\ttransformer.set_mean('data', np.array([104,117,123])) # mean pixel\n",
    "\ttransformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "\ttransformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "\tnet.blobs['data'].reshape(1,3,config['input_height'], config['input_width'])\n",
    "\n",
    "\timage=caffe.io.load_image(os.path.join(config['img_dir'], config['image_name']))\n",
    "\ttransformed_image = transformer.preprocess('data', image)\n",
    "\tnet.blobs['data'].data[...] = transformed_image\n",
    "\treturn net, image\n",
    "\n",
    "\n",
    "def extract_detections(detections, det_score_threshold, image_height, image_width):\n",
    "\tdet_conf = detections[0,0,:,2]\n",
    "\tdet_x1 = detections[0,0,:,7]\n",
    "\tdet_y1 = detections[0,0,:,8]\n",
    "\tdet_x2 = detections[0,0,:,9]\n",
    "\tdet_y2 = detections[0,0,:,10]\n",
    "\tdet_x3 = detections[0,0,:,11]\n",
    "\tdet_y3 = detections[0,0,:,12]\n",
    "\tdet_x4 = detections[0,0,:,13]\n",
    "\tdet_y4 = detections[0,0,:,14]\n",
    "\t# Get detections with confidence higher than 0.6.\n",
    "\ttop_indices = [i for i, conf in enumerate(det_conf) if conf >= det_score_threshold]\n",
    "\ttop_conf = det_conf[top_indices]\n",
    "\ttop_x1 = det_x1[top_indices]\n",
    "\ttop_y1 = det_y1[top_indices]\n",
    "\ttop_x2 = det_x2[top_indices]\n",
    "\ttop_y2 = det_y2[top_indices]\n",
    "\ttop_x3 = det_x3[top_indices]\n",
    "\ttop_y3 = det_y3[top_indices]\n",
    "\ttop_x4 = det_x4[top_indices]\n",
    "\ttop_y4 = det_y4[top_indices]\n",
    "\n",
    "\tbboxes=[]\n",
    "\tfor i in xrange(top_conf.shape[0]):\n",
    "\t\tx1 = int(round(top_x1[i] * image_width))\n",
    "\t\ty1 = int(round(top_y1[i] * image_height))\n",
    "\t\tx2 = int(round(top_x2[i] * image_width))\n",
    "\t\ty2 = int(round(top_y2[i] * image_height))\n",
    "\t\tx3 = int(round(top_x3[i] * image_width))\n",
    "\t\ty3 = int(round(top_y3[i] * image_height))\n",
    "\t\tx4 = int(round(top_x4[i] * image_width))\n",
    "\t\ty4 = int(round(top_y4[i] * image_height))\n",
    "\t\tx1 = max(1, min(x1, image_width - 1))\n",
    "\t\tx2 = max(1, min(x2, image_width - 1))\n",
    "\t\tx3 = max(1, min(x3, image_width - 1))\n",
    "\t\tx4 = max(1, min(x4, image_width - 1))\n",
    "\t\ty1 = max(1, min(y1, image_height - 1))\n",
    "\t\ty2 = max(1, min(y2, image_height - 1))\n",
    "\t\ty3 = max(1, min(y3, image_height - 1))\n",
    "\t\ty4 = max(1, min(y4, image_height - 1))\n",
    "\t\tscore = top_conf[i]\n",
    "\t\tbbox=[x1,y1,x2,y2,x3,y3,x4,y4,score]\n",
    "\t\tbboxes.append(bbox)\n",
    "\treturn bboxes\n",
    "\n",
    "def apply_quad_nms(bboxes, overlap_threshold):\n",
    "\tdt_lines = sorted(bboxes, key=lambda x:-float(x[8]))\n",
    "\tnms_flag = nms(dt_lines, overlap_threshold)\n",
    "\tresults=[]\n",
    "\tfor k,dt in enumerate(dt_lines):\n",
    "\t\tif nms_flag[k]:\n",
    "\t\t\tif dt not in results:\n",
    "\t\t\t\tresults.append(dt)\n",
    "\treturn results\n",
    "\n",
    "def save_and_visu(image, results, config):\n",
    "\timage_name=config['image_name']\n",
    "\tdet_save_path=os.path.join(config['det_save_dir'], image_name.split('.')[0]+'.txt')\n",
    "\tdet_fid = open(det_save_path, 'wt')\n",
    "\tif config['visu_detection']:\n",
    "\t\t# visulization\n",
    "\t\tplt.clf()\n",
    "\t\tplt.imshow(image)\n",
    "\t\tcurrentAxis = plt.gca()\n",
    "\tfor result in results:\n",
    "\t\tscore = result[-1]\n",
    "\t\tx1 = result[0]\n",
    "\t\ty1 = result[1]\n",
    "\t\tx2 = result[2]\n",
    "\t\ty2 = result[3]\n",
    "\t\tx3 = result[4]\n",
    "\t\ty3 = result[5]\n",
    "\t\tx4 = result[6]\n",
    "\t\ty4 = result[7]\n",
    "\t\tresult_str=str(x1)+','+str(y1)+','+str(x2)+','+str(y2)+','+str(x3)+','+str(y3)+','+str(x4)+','+str(y4)+','+str(score)+'\\r\\n'\n",
    "\t\tdet_fid.write(result_str)\n",
    "\t\tif config['visu_detection']:\n",
    "\t\t\tquad = np.array([[x1,y1],[x2,y2],[x3,y3],[x4,y4]])\n",
    "\t\t\tcolor_quad='r'\n",
    "\t\t\tcurrentAxis.add_patch(plt.Polygon(quad, fill=False, edgecolor=color_quad, linewidth=2))\n",
    "\n",
    "\tdet_fid.close()\n",
    "\tif config['visu_detection']:\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.savefig(config['det_visu_path'], dpi=300)\n",
    "\n",
    "def visu_rec_results(image, rec_save_dir, f_score_threshold):\n",
    "\timage_name=config['image_name']\n",
    "\tresult_file_path = os.path.join(rec_save_dir, image_name.split('.')[0]+'.txt')\n",
    "\trec_result_fid = open(result_file_path, 'r')\n",
    "\tplt.clf()\n",
    "\tplt.imshow(image)\n",
    "\tcurrentAxis = plt.gca()\n",
    "\tfor line in rec_result_fid.readlines():\n",
    "\t\tline=line.strip()\n",
    "\t\tx1=int(line.split(',')[0])\n",
    "\t\ty1=int(line.split(',')[1])\n",
    "\t\tx2=int(line.split(',')[2])\n",
    "\t\ty2=int(line.split(',')[3])\n",
    "\t\tx3=int(line.split(',')[4])\n",
    "\t\ty3=int(line.split(',')[5])\n",
    "\t\tx4=int(line.split(',')[6])\n",
    "\t\ty4=int(line.split(',')[7])\n",
    "\t\tdet_score=float(line.split(',')[8])\n",
    "\t\trec_score=float(line.split(',')[10])\n",
    "\t\trec_str=line.split(',')[9]\n",
    "\t\tf_score = 2*math.exp(det_score)*math.exp(rec_score)/(math.exp(det_score)+math.exp(rec_score))\n",
    "\t\tprint(f_score)\n",
    "\t\tif f_score>f_score_threshold:\n",
    "\t\t\tquad = np.array([[x1,y1],[x2,y2],[x3,y3],[x4,y4]])\n",
    "\t\t\tcolor_quad='r'\n",
    "\t\t\tcurrentAxis.add_patch(plt.Polygon(quad, fill=False, edgecolor=color_quad, linewidth=2))\n",
    "\t\t\tcurrentAxis.text(x1, y1, rec_str, fontsize=5)\n",
    "\n",
    "\trec_result_fid.close()\n",
    "\tplt.axis('off')\n",
    "\tplt.savefig(config['rec_visu_path'], dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "\t'model_def' : './models/deploy.prototxt',\n",
    "\t'model_weights' : './models/model_icdar15.caffemodel',\n",
    "\t'img_dir' : './demo_images/',\n",
    "\t'image_name' : 'demo.jpg',\n",
    "\t'det_visu_path' : './demo_images/demo_det_result.jpg',\n",
    "\t'rec_visu_path' : './demo_images/demo_rec_result.jpg',\n",
    "\t'det_save_dir' : './demo_images/detection_result/',\n",
    "\t'rec_save_dir' : './demo_images/recognition_result/',\n",
    "\t'crop_dir' : './demo_images/crops/',\n",
    "\t'lexicon_path' : './crnn/data/icdar_generic_lexicon.txt',\n",
    "\t'use_lexcion' : True,\n",
    "\t'input_height' : 768,\n",
    "\t'input_width' : 768,\n",
    "\t'overlap_threshold' : 0.2,\n",
    "\t'det_score_threshold' : 0.1,\n",
    "\t'f_score_threshold' : 0.7,\n",
    "\t'visu_detection' : True,\n",
    "\t'visu_recognition': False,\n",
    "\t'apply_recognition' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detection\n",
    "root_dir=\"data/text/\"\n",
    "for root, dirs, files in os.walk(os.path.join(root_dir,'image_1000/')):\n",
    "        #image path\n",
    "        for file in files:\n",
    "            image_name=file\n",
    "            #label_name=file[0:-4]+'.txt'\n",
    "            image_path=os.path.join(root_dir,'image_1000/',image_name)\n",
    "            #sub_dir='train_images'\n",
    "            config['image_name']=image_name\n",
    "            net, image= prepare_network(config)\n",
    "            image_height, image_width, channels=image.shape\n",
    "            detections = net.forward()['detection_out']\n",
    "            # Parse the outputs.\n",
    "            bboxes = extract_detections(detections, config['det_score_threshold'], image_height, image_width)\n",
    "            # apply non-maximum suppression\n",
    "            results = apply_quad_nms(bboxes, config['overlap_threshold'])\n",
    "            save_and_visu(image, results, config)\n",
    "            print('detection finished')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
